import os
import torch
import logging
import argparse
from utils import factory
from utils.data_manager import DataManager
from datetime import datetime
import time


def load_model_weights(model, model_path):
    """
    åŠ è½½æ¨¡å‹æƒé‡
    :param model: æ¨¡å‹å®ä¾‹
    :param model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
    """
    state_dict = torch.load(model_path, map_location=torch.device('cuda'))
    logging.info(f"State_dict keys: {state_dict.keys()}")

    # æ£€æŸ¥æ¨¡å‹çš„é”®å
    model_keys = model._network.state_dict().keys()
    logging.info(f"Model keys: {model_keys}")

    # æ£€æŸ¥ä¸åŒ¹é…çš„é”®
    missing_keys = [key for key in model_keys if key not in state_dict]
    unexpected_keys = [key for key in state_dict if key not in model_keys]

    if missing_keys:
        logging.warning(f"Missing keys in state_dict: {missing_keys}")
    if unexpected_keys:
        logging.warning(f"Unexpected keys in state_dict: {unexpected_keys}")

    # åŠ è½½æƒé‡ï¼Œå¿½ç•¥ä¸åŒ¹é…çš„é”®
    model._network.load_state_dict({k: v for k, v in state_dict.items() if k in model_keys})
    logging.info(f"Model weights loaded from {model_path}")

# def inference(args):
#     """
#     æ¨¡å‹æ¨ç†éªŒè¯
#     :param args: å‚æ•°å­—å…¸
#     """
#     # è®¾ç½®æ—¥å¿—
#     logfilename = f"logs/inference_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log"
#     os.makedirs("logs", exist_ok=True)
#     logging.basicConfig(
#         level=logging.INFO,
#         format="%(asctime)s [%(filename)s] => %(message)s",
#         handlers=[
#             logging.FileHandler(filename=logfilename),
#             logging.StreamHandler(),
#         ],
#     )
#     logging.info("Starting inference...")
#
#     # è®¾ç½®éšæœºç§å­
#     torch.manual_seed(args["seed"])
#     torch.cuda.manual_seed(args["seed"])
#     torch.cuda.manual_seed_all(args["seed"])
#     torch.backends.cudnn.deterministic = True
#     torch.backends.cudnn.benchmark = False
#
#     # åŠ è½½æ•°æ®ç®¡ç†å™¨
#     data_manager = DataManager(
#         dataset_name=args["dataset"],
#         shuffle=args["shuffle"],
#         seed=args["seed"],
#         init_cls=args["init_cls"],
#         increment=args["increment"],
#     )
#
#     # åŠ è½½æ¨¡å‹
#     model = factory.get_model(args["model_name"], args)
#
#     # åŠ è½½æŒ‡å®šä»»åŠ¡çš„æ¨¡å‹æƒé‡
#     task_id = args["task_id"]
#     model_path = os.path.join(args["model_dir"], f"task_{task_id}.pth")
#     if not os.path.exists(model_path):
#         raise FileNotFoundError(f"Model weights file not found: {model_path}")
#
#     load_model_weights(model, model_path)
#
#     # æ¨ç†å¼€å§‹
#     model.eval()
#     test_loader = data_manager.get_test_loader(task_id)
#     correct = 0
#     total = 0
#
#     all_preds = []
#     all_labels = []
#
#     device = torch.device(args["device"])
#     model.to(device)
#
#     start_time = time.time()
#     with torch.no_grad():
#         for inputs, targets in test_loader:
#             inputs, targets = inputs.to(device), targets.to(device)
#             outputs = model(inputs)
#             _, predicted = torch.max(outputs, 1)
#             total += targets.size(0)
#             correct += (predicted == targets).sum().item()
#
#             all_preds.extend(predicted.cpu().tolist())
#             all_labels.extend(targets.cpu().tolist())
#     end_time = time.time()
#
#     # å‡†ç¡®ç‡å’Œè€—æ—¶ç»Ÿè®¡
#     accuracy = 100 * correct / total
#     elapsed = end_time - start_time
#
#     logging.info(f"âœ… æ¨ç†å®Œæˆï¼")
#     logging.info(f"ğŸ“Š Task {task_id} Accuracy: {accuracy:.2f}%")
#     logging.info(f"â±ï¸  è€—æ—¶: {elapsed:.2f} ç§’")
#     print(f"\nâœ… æ¨ç†å®Œæˆï¼ğŸ“Š Accuracy: {accuracy:.2f}%, â±ï¸ Time: {elapsed:.2f}s")
#
#     # ä¿å­˜é¢„æµ‹ç»“æœ
#     output_file = os.path.join("logs", f"predictions_task_{task_id}.txt")
#     with open(output_file, "w") as f:
#         for pred in all_preds:
#             f.write(f"{pred}\n")
#     logging.info(f"ğŸ“ é¢„æµ‹ç»“æœä¿å­˜åˆ°: {output_file}")
def inference(args):
    """
    æ¨¡å‹æ¨ç†éªŒè¯
    :param args: å‚æ•°å­—å…¸
    """
    # æ‰“å° args çš„å€¼
    for key, value in args.items():
        logging.info(f"{key}: {value}")

    # è®¾ç½®æ—¥å¿—
    logfilename = f"logs/inference_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log"
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(filename)s] => %(message)s",
        handlers=[
            logging.FileHandler(filename=logfilename),
            logging.StreamHandler(),
        ],
    )
    logging.info("Starting inference...")

    # æ‰“å° args["device"] çš„å€¼
    logging.info(f"Device: {args['device']}")

    # æ£€æŸ¥ args["device"] çš„å€¼æ˜¯å¦æœ‰æ•ˆ
    if not isinstance(args["device"], list) or len(args["device"]) == 0:
        raise ValueError("Invalid device list. Please provide a valid device list, e.g., ['cuda:0'] or ['cpu']")

    device_str = args["device"][0]
    valid_devices = ["cpu", "cuda", "cuda:0", "cuda:1", "cuda:2", "cuda:3"]
    if device_str not in valid_devices:
        raise ValueError(f"Invalid device string: {device_str}. Please provide a valid device string, e.g., 'cuda:0' or 'cpu'")

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args["seed"])
    torch.cuda.manual_seed(args["seed"])
    torch.cuda.manual_seed_all(args["seed"])
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    # åŠ è½½æ•°æ®ç®¡ç†å™¨
    data_manager = DataManager(
        dataset_name=args["dataset"],
        shuffle=args["shuffle"],
        seed=args["seed"],
        init_cls=args["init_cls"],
        increment=args["increment"],
    )

    # åŠ è½½æ¨¡å‹
    model = factory.get_model(args["model_name"], args)

    # åŠ è½½æŒ‡å®šä»»åŠ¡çš„æ¨¡å‹æƒé‡
    task_id = args["task_id"]
    model_name = args["model_name"]
    dataset = args["dataset"]
    init_cls = args["init_cls"]
    increment = args["increment"]
    seed = args["seed"]
    convnet_type = args["convnet_type"]
    time_str = args["time_str"]

    model_path = os.path.join(args["model_dir"], f"task_{task_id}.pth")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model weights file not found: {model_path}")

    load_model_weights(model, model_path)

    # è¿›è¡Œæ¨ç†éªŒè¯
    model.eval()  # ç¡®ä¿è°ƒç”¨ eval æ–¹æ³•
    test_loader = data_manager.get_test_loader(task_id)
    correct = 0
    total = 0

    device = torch.device(device_str)  # ç¡®ä¿è®¾å¤‡ç±»å‹æ­£ç¡®
    model.to(device)  # ç¡®ä¿è°ƒç”¨ to æ–¹æ³•

    with torch.no_grad():
        for idx, inputs, targets in test_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            total += targets.size(0)
            correct += (predicted == targets).sum().item()

    accuracy = 100 * correct / total
    logging.info(f"Task {task_id} Accuracy: {accuracy:.2f}%")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Inference script for PyCIL")
    parser.add_argument("--data_dir", type=str, default="seed_dataset2", help="è·¯å¾„åŒ…å« train/val/test")
    parser.add_argument("--model_dir", type=str, default="models/der/iseeds/20/1/1993/resnet32/2025-05-28_21-25-31", help="ä¿å­˜ task_0.pth çš„ç›®å½•")
    parser.add_argument("--model_name", type=str, default="der", help="æ¨¡å‹åç§°ï¼Œéœ€ä¸ factory ä¸­ä¸€è‡´")
    parser.add_argument("--prefix", type=str, default="reproduce", help="æ—¥å¿—å‰ç¼€ï¼ˆç”¨äºä¸€äº›æ¨¡å‹åˆå§‹åŒ–ï¼‰")
    parser.add_argument("--seed", type=int, default=1993)
    parser.add_argument("--convnet_type", type=str, default="resnet32")
    parser.add_argument("--memory_size", type=int, default=200)
    parser.add_argument("--device", type=str,  default=["0"])
    parser.add_argument("--dataset", type=str, default="iseeds", help="æ•°æ®é›†åç§°")
    parser.add_argument("--init_cls", type=int, default=20, help="åˆå§‹ç±»åˆ«æ•°é‡")
    parser.add_argument("--increment", type=int, default=1, help="ç±»åˆ«å¢é‡")
    parser.add_argument("--shuffle", action="store_true", help="æ˜¯å¦æ‰“ä¹±æ•°æ®é›†")
    parser.add_argument("--task_id", type=int, default=0, help="ä»»åŠ¡ç¼–å·")
    parser.add_argument("--time_str", type=str, default=datetime.now().strftime('%Y-%m-%d_%H-%M-%S'), help="æ—¶é—´æˆ³ï¼Œç”¨äºåŒ¹é…æƒé‡æ–‡ä»¶")
    args = parser.parse_args()

    args = vars(args)
    inference(args)

 # python inference.py --data_dir seed_dataset2 --model_dir logs/der/iseeds/20/1/reproduce_1993_resnet32 --model_name der --prefix reproduce --seed 1993 --convnet_type resnet32 --device cuda:0